[[EXAMPLES]]

[PRAW SCRAPING]

Arguments:

    [-r <subreddit> <(h|n|c|t|r|s)> <n_results_or_keywords> [<optional_time_filter>]] 
        [-y]
        [--csv]
        [--rules]
    [-u <redditor> <n_results>] 
    [-c <submission_url> <n_results>]
        [--raw] 
    [-b]
        [--csv]

All scrape results are exported to JSON by default.

You can run all of these scrapers in one call.

SUBREDDITS

    Get the first 10 posts in r/askreddit in the Hot category and export to JSON:

        $ poetry run python Urs.py -r askreddit h 10

    Search for "United States of America" in r/worldnews and export to CSV by including the `--csv` flag:

        $ poetry run python Urs.py -r worldnews s "United States of America" --csv

    You can apply a time filter when scraping Subreddit categories Controversial, Top, or Search:
    (Scraping Search results from r/learnprogramming from the past month)

        $ poetry run python Urs.py -r learnprogramming s "python developer" month

    You can skip the settings confirmation table and immediately scrape by including the `-y` flag:

        $ poetry run python Urs.py -r cscareerquestions s "job" year -y

    You can add the Subreddit's rules in the scrape results by including the `--rules` flag. 
    This only works when you export to JSON:

        $ poetry run python Urs.py -r wallstreetbets t 25 year --rules

    You can also still use URS v1.0.0 (SUBREDDIT SCRAPING ONLY), but you cannot include 
    this flag with any items besides export options:

        $ poetry run python Urs.py -b

        $ poetry run python Urs.py -b --csv

REDDITORS

    Scraping 15 results from u/spez's Reddit account:

        $ poetry run python Urs.py -u spez 15

SUBMISSION COMMENTS

    Scraping 25 comments from this r/TIFU post. Returns a structured JSON file:

        $ poetry run python Urs.py -c https://www.reddit.com/r/tifu/comments/a99fw9/tifu_by_buying_everyone_an_ancestrydna_kit_and/ 25

    Scraping all comments from the same r/TIFU post. Returns a structured JSON file:
    
        $ poetry run python Urs.py -c https://www.reddit.com/r/tifu/comments/a99fw9/tifu_by_buying_everyone_an_ancestrydna_kit_and/ 0

    You can also return comments in raw format by including the `--raw` flag.
    Ie. top-level first, followed by second-level, then third-level, etc.:

        $ poetry run python Urs.py -c https://www.reddit.com/r/tifu/comments/a99fw9/tifu_by_buying_everyone_an_ancestrydna_kit_and/ 25 --raw
        
        $ poetry run python Urs.py -c https://www.reddit.com/r/tifu/comments/a99fw9/tifu_by_buying_everyone_an_ancestrydna_kit_and/ 0 --raw

[PRAW LIVESTREAM SCRAPING]

Arguments:

    [-lr <subreddit>]
    [-lu <redditor>]

        [--nosave]
        [--stream-submissions]

LIVE SUBREDDIT STREAM

    Livestream comments created in r/AskReddit. Writes livestream results to a JSON file:

        $ poetry run python Urs.py -lr askreddit

    Or livestream submissions created in r/AskReddit:

        $ poetry run python Urs.py -lr askreddit --stream-submissions

    If you do not want to save livestream results to file, include the `--nosave` flag:

        $ poetry run python Urs.py -lr askreddit --stream-submissions --nosave

LIVE REDDITOR STREAM

    Livestream comments by u/spez. Writes livestream results to a JSON file:

        $ poetry run python Urs.py -lu spez

    Or livestream submissions by u/spez:

        $ poetry run python Urs.py -lu spez --stream-submissions

    If you do not want to save livestream results to file, include the `--nosave` flag:

        $ poetry run python Urs.py -lu spez --stream-submissions --nosave

[ANALYTICAL TOOLS]

Arguments:

    [-f <file_path>]
        [--csv]
    [-wc <file_path> [<optional_export_format>]
        [--nosave]

Word frequencies are exported to JSON by default.

Wordclouds are exported to PNG by default.

You can run both of these tools in one call.

WORD FREQUENCIES

    Only return a count of words that are present in submission titles, bodies, and/or comments. 
    An example file path is given:

        $ poetry run python Urs.py -f ../scrapes/02-15-2021/subreddits/askreddit-hot-100-results.json

    You can also export to CSV instead by including the `--csv` flag:

        $ poetry run python Urs.py -f ../scrapes/02-15-2021/subreddits/askreddit-hot-100-results.json --csv

WORDCLOUD

    You can also generate a wordcloud based on word frequencies:
    
        $ poetry run python Urs.py -wc ../scrapes/02-15-2021/subreddits/askreddit-hot-100-results.json

OPTIONAL EXPORT FORMAT

    You can export to formats other than PNG by providing the format after the file path.
    See the help menu for a full list of options. Exporting the wordcloud to JPG:

        $ poetry run python Urs.py -wc ../scrapes/02-15-2021/subreddits/askreddit-hot-100-results.json jpg

DISPLAY INSTEAD OF SAVING

    If you do not wish to save the wordcloud to file, include the `--nosave` flag:

        $ poetry run python Urs.py -wc ../scrapes/02-15-2021/subreddits/askreddit-hot-100-results.json --nosave

[UTILITIES]

Arguments:

    [-t [<optional_date>]]
    [--check]

DISPLAY SCRAPES DIRECTORY TREE

    You can display the scrapes directory tree for the current day by using the `-t` flag:

        $ poetry run python Urs.py -t

    You can also include a date to display the directory tree for that date.
    The following date formats are accepted: MM-DD-YYYY, MM/DD/YYYY:

        $ poetry run python Urs.py -t 06-02-2021
        $ poetry run python Urs.py -t 06/02/2021

CHECK PRAW RATE LIMITS

    You can quickly check the rate limits for your account by using the `--check` flag:

        $ poetry run python Urs.py --check
